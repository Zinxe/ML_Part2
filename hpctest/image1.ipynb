{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ec1a18-26ce-478e-9155-156bb58fb6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUNG1-002 ROI volume shape: (222, 333, 333)\n",
      "LUNG1-003 ROI volume shape: (214, 333, 333)\n",
      "LUNG1-005 ROI volume shape: (182, 333, 333)\n",
      "LUNG1-002 features: {'volume_mm3': 515210.625, 'surface_mm2': 76237.54357674009, 'max_diameter_mm': 293.2212584678799, 'compactness': 1669.3102586993753}\n",
      "LUNG1-003 features: {'volume_mm3': 369727.875, 'surface_mm2': 60603.535128362884, 'max_diameter_mm': 274.6759559269997, 'compactness': 1628.2814872188887}\n",
      "LUNG1-005 features: {'volume_mm3': 319146.75, 'surface_mm2': 65147.50703303793, 'max_diameter_mm': 243.24066726883004, 'compactness': 2714.6419241472163}\n",
      "Done,3 in total\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "\n",
    "DATA_DIR = \"/mnt/e/Block_2/Machine_Learning/ASS_Part2/Project/testdata\"\n",
    "\n",
    "# get 3D volume\n",
    "def read_dicom_series(folder_path):\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    dicom_names = reader.GetGDCMSeriesFileNames(folder_path)\n",
    "    reader.SetFileNames(dicom_names)\n",
    "    return reader.Execute()\n",
    "\n",
    "# get CT Series UID from segmentation\n",
    "def get_series_uid_from_seg(seg_path):\n",
    "    return pydicom.dcmread(seg_path).ReferencedSeriesSequence[0].SeriesInstanceUID\n",
    "\n",
    "# matching UID\n",
    "def find_ct_folder_by_uid(folder, uid):\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(\".dcm\"):\n",
    "                try:\n",
    "                    if pydicom.dcmread(os.path.join(root, f), stop_before_pixels=True).SeriesInstanceUID == uid:\n",
    "                        return root\n",
    "                except: continue\n",
    "    return None\n",
    "\n",
    "# calculate Z-coordinate\n",
    "def get_z_coords(sitk_img):\n",
    "    sz, sp, org, dir3 = sitk_img.GetSize(), sitk_img.GetSpacing(), sitk_img.GetOrigin(), sitk_img.GetDirection()\n",
    "    return [org[2] + i * sp[2] * dir3[8] for i in range(sz[2])]\n",
    "\n",
    "# matching z\n",
    "def align_segmentation_by_z(seg_img, seg_z, ct_z):\n",
    "    zset = set(round(z, 1) for z in ct_z)\n",
    "    return sitk.GetArrayFromImage(seg_img)[[i for i, z in enumerate(seg_z) if round(z, 1) in zset]]\n",
    "\n",
    "# resample（1mm*3）\n",
    "def resample_to_spacing(image_sitk, new_spacing=(1.0, 1.0, 1.0), interpolator=sitk.sitkLinear):\n",
    "    original_spacing = image_sitk.GetSpacing()\n",
    "    original_size = image_sitk.GetSize()\n",
    "    new_size = [\n",
    "        int(round(original_size[i] * (original_spacing[i] / new_spacing[i])))\n",
    "        for i in range(3)\n",
    "    ]\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetOutputSpacing(new_spacing)\n",
    "    resampler.SetSize(new_size)\n",
    "    resampler.SetOutputDirection(image_sitk.GetDirection())\n",
    "    resampler.SetOutputOrigin(image_sitk.GetOrigin())\n",
    "    resampler.SetInterpolator(interpolator)\n",
    "    return resampler.Execute(image_sitk)\n",
    "\n",
    "# normalise to [0,1]\n",
    "def normalize_gray_roi_adaptive(image_np, mask_np, min_percentile=1, max_percentile=99):\n",
    "    roi = image_np[mask_np > 0]\n",
    "    if roi.size == 0:\n",
    "        return np.zeros_like(image_np)\n",
    "    vmin, vmax = np.percentile(roi, [min_percentile, max_percentile])\n",
    "    image_clipped = np.clip(image_np, vmin, vmax)\n",
    "    return (image_clipped - vmin) / (vmax - vmin + 1e-6)\n",
    "\n",
    "# main\n",
    "def load_aligned_ct_and_mask(patient_folder, target_spacing=(1.5, 1.5, 1.5)):\n",
    "    seg_path = next((os.path.join(root, f) for root, _, files in os.walk(patient_folder)\n",
    "                     for f in files if \"segmentation\" in root.lower() and f.endswith(\".dcm\")), None)\n",
    "    if not seg_path: return None, None, None\n",
    "\n",
    "    uid = get_series_uid_from_seg(seg_path)\n",
    "    ct_folder = find_ct_folder_by_uid(patient_folder, uid)\n",
    "    if not ct_folder: return None, None, None\n",
    "\n",
    "    ct_img = read_dicom_series(ct_folder)\n",
    "    seg_img = sitk.ReadImage(seg_path)\n",
    "\n",
    "    # Resample to same spacing (1mm)\n",
    "    ct_img = resample_to_spacing(ct_img, new_spacing=target_spacing)\n",
    "    \n",
    "    # resample segmentation\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetReferenceImage(ct_img)\n",
    "    resampler.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    seg_img = resampler.Execute(seg_img)\n",
    "\n",
    "    # z coordinate alignment\n",
    "    ct_z = get_z_coords(ct_img)\n",
    "    seg_z = get_z_coords(seg_img)\n",
    "    mask = align_segmentation_by_z(seg_img, seg_z, ct_z)\n",
    "\n",
    "    image = sitk.GetArrayFromImage(ct_img)\n",
    "    image = normalize_gray_roi_adaptive(image, mask)\n",
    "\n",
    "    # output\n",
    "    return image, mask, target_spacing\n",
    "\n",
    "base_dir = os.path.join(DATA_DIR, \"dataset1\")\n",
    "\n",
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue  # skip non-folders\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "\n",
    "    if image is not None:\n",
    "        roi = image * (mask > 0)\n",
    "        print(f\"{patient_id} ROI volume shape: {roi.shape}\")\n",
    "    else:\n",
    "        print(f\"{patient_id} fail\")\n",
    "\n",
    "# Extraction of tumour 3D shape features based on marching cubes algorithm\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage as ski\n",
    "from skimage import io, data, filters, measure, morphology\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import skimage.measure\n",
    "from scipy.spatial.distance import  pdist\n",
    "\n",
    "def extract_shape_features(mask, spacing=(1.0, 1.0, 1.0)):\n",
    "    verts, faces, _, _ = measure.marching_cubes(mask, level=0.5, spacing=spacing)\n",
    "\n",
    "    # surface area\n",
    "    surface_area = measure.mesh_surface_area(verts, faces)\n",
    "\n",
    "    # volumetric\n",
    "    voxel_volume = np.prod(spacing)\n",
    "    volume = np.sum(mask > 0) * voxel_volume\n",
    "\n",
    "    # maximum diameter\n",
    "    if len(verts) >= 2:\n",
    "        max_diameter = pdist(verts).max()\n",
    "    else:\n",
    "        max_diameter = 0.0\n",
    "\n",
    "    # Compactness\n",
    "    if volume > 0:\n",
    "        compactness = (surface_area ** 3) / (volume ** 2)\n",
    "    else:\n",
    "        compactness = 0.0\n",
    "\n",
    "    return {\n",
    "        \"volume_mm3\": volume,\n",
    "        \"surface_mm2\": surface_area,\n",
    "        \"max_diameter_mm\": max_diameter,\n",
    "        \"compactness\": compactness\n",
    "    }\n",
    "\n",
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "    if image is None or mask is None:\n",
    "        print(f\"{patient_id} skip\")\n",
    "        continue\n",
    "\n",
    "    features = extract_shape_features(mask, spacing)\n",
    "    print(f\"{patient_id} features:\", features)\n",
    "\n",
    "# GLCM\n",
    "def gray_level_cooccurrence_features(img, mask, levels=32):\n",
    "    bin_img = (img * (levels - 1)).astype(np.uint8)\n",
    "    glcm = _calculate_glcm2(bin_img, mask, levels)\n",
    "    glcm = glcm / np.sum(glcm)\n",
    "\n",
    "    ix = np.arange(1, levels+1)[:, None, None].astype(np.float64)\n",
    "    iy = np.arange(1, levels+1)[None, :, None].astype(np.float64)\n",
    "\n",
    "    ux = np.mean(glcm, axis=0, keepdims=True)\n",
    "    uy = np.mean(glcm, axis=1, keepdims=True)\n",
    "    sigma_x = np.std(glcm, axis=0, keepdims=True)\n",
    "    sigma_y = np.std(glcm, axis=1, keepdims=True)\n",
    "\n",
    "    # downscale protection\n",
    "    sigma_x[sigma_x < 1e-3] = 1e-3\n",
    "    sigma_y[sigma_y < 1e-3] = 1e-3\n",
    "\n",
    "    features = {\n",
    "        \"contrast\": np.mean(np.sum((ix - iy) ** 2 * glcm, axis=(0, 1))),\n",
    "        \"correlation\": np.mean(np.sum((ix * iy * glcm - ux * uy) / (sigma_x * sigma_y + 1e-6), axis=(0, 1))),\n",
    "        \"dissimilarity\": np.mean(np.sum(np.abs(ix - iy) * glcm, axis=(0, 1))),\n",
    "        \"homogeneity\": np.mean(np.sum(glcm / (1 + np.abs(ix - iy)), axis=(0, 1))),\n",
    "    }\n",
    "\n",
    "    return features\n",
    "\n",
    "# GLCM2\n",
    "def _calculate_glcm2(img, mask, nbins):\n",
    "    out = np.zeros((nbins, nbins, 13))\n",
    "    offsets = [\n",
    "        (1, 0, 0), (0, 1, 0), (0, 0, 1),\n",
    "        (1, 1, 0), (-1, 1, 0), (1, 0, 1),\n",
    "        (-1, 0, 1), (0, 1, 1), (0, -1, 1),\n",
    "        (1, 1, 1), (-1, 1, 1), (1, -1, 1), (1, 1, -1)\n",
    "    ]\n",
    "    matrix = np.array(img)\n",
    "    matrix[mask <= 0] = nbins\n",
    "    s = matrix.shape\n",
    "    bins = np.arange(0, nbins + 1)\n",
    "\n",
    "    for i, offset in enumerate(offsets):\n",
    "        matrix1 = np.ravel(matrix[max(offset[0], 0):s[0]+min(offset[0], 0),\n",
    "                                  max(offset[1], 0):s[1]+min(offset[1], 0),\n",
    "                                  max(offset[2], 0):s[2]+min(offset[2], 0)])\n",
    "\n",
    "        matrix2 = np.ravel(matrix[max(-offset[0], 0):s[0]+min(-offset[0], 0),\n",
    "                                  max(-offset[1], 0):s[1]+min(-offset[1], 0),\n",
    "                                  max(-offset[2], 0):s[2]+min(-offset[2], 0)])\n",
    "\n",
    "        try:\n",
    "            out[:, :, i] = np.histogram2d(matrix1, matrix2, bins=bins)[0]\n",
    "        except Exception as e:\n",
    "            print(f\"GLCM histogram failed for offset {offset}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return out\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = os.path.join(DATA_DIR, \"dataset1\")\n",
    "all_features = []\n",
    "\n",
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    if not patient_id.startswith(\"LUNG1-\"):\n",
    "        continue\n",
    "\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "\n",
    "    if image is not None and mask is not None:\n",
    "        image = normalize_gray_roi_adaptive(image, mask)\n",
    "        glcm = gray_level_cooccurrence_features(image, mask)\n",
    "\n",
    "        glcm[\"patient_id\"] = patient_id\n",
    "        all_features.append(glcm)\n",
    "    else:\n",
    "        print(f\"{patient_id} skip\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "base_dir = os.path.join(DATA_DIR, \"dataset1\")\n",
    "all_features = []\n",
    "\n",
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    if not patient_id.startswith(\"LUNG1-\"):\n",
    "        continue\n",
    "\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "    if image is None or mask is None:\n",
    "        print(f\"{patient_id} skip\")\n",
    "        continue\n",
    "\n",
    "    image = normalize_gray_roi_adaptive(image, mask)\n",
    "    shape_feats = extract_shape_features(mask, spacing)\n",
    "    glcm_feats = gray_level_cooccurrence_features(image, mask)\n",
    "\n",
    "    features = {\"patient_id\": patient_id}\n",
    "    features.update(shape_feats)\n",
    "    features.update(glcm_feats)\n",
    "    all_features.append(features)\n",
    "\n",
    "# Save the result as a csv file\n",
    "output_path = \"../result/combined_features.csv\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "df = pd.DataFrame(all_features)\n",
    "df.to_csv(\"../result/features1.csv\", index=False)\n",
    "print(f\"Done,{len(df)} in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b23bbd-0d1e-4d55-a34c-9e388650cdee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
