{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ec1a18-26ce-478e-9155-156bb58fb6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUNG1-001 ROI volume shape: (268, 333, 333)\n",
      "LUNG1-002 ROI volume shape: (222, 333, 333)\n",
      "LUNG1-003 ROI volume shape: (214, 333, 333)\n",
      "LUNG1-004 ROI volume shape: (228, 333, 333)\n",
      "LUNG1-005 ROI volume shape: (182, 333, 333)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "\n",
    "DATA_DIR = \"/mnt/e/Block_2/Machine_Learning/ASS_Part2/Project/testdata\"\n",
    "\n",
    "# get 3D volume\n",
    "def read_dicom_series(folder_path):\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    dicom_names = reader.GetGDCMSeriesFileNames(folder_path)\n",
    "    reader.SetFileNames(dicom_names)\n",
    "    return reader.Execute()\n",
    "\n",
    "# get CT Series UID from segmentation\n",
    "def get_series_uid_from_seg(seg_path):\n",
    "    return pydicom.dcmread(seg_path).ReferencedSeriesSequence[0].SeriesInstanceUID\n",
    "\n",
    "# matching UID\n",
    "def find_ct_folder_by_uid(folder, uid):\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(\".dcm\"):\n",
    "                try:\n",
    "                    if pydicom.dcmread(os.path.join(root, f), stop_before_pixels=True).SeriesInstanceUID == uid:\n",
    "                        return root\n",
    "                except: continue\n",
    "    return None\n",
    "\n",
    "# calculate Z-coordinate\n",
    "def get_z_coords(sitk_img):\n",
    "    sz, sp, org, dir3 = sitk_img.GetSize(), sitk_img.GetSpacing(), sitk_img.GetOrigin(), sitk_img.GetDirection()\n",
    "    return [org[2] + i * sp[2] * dir3[8] for i in range(sz[2])]\n",
    "\n",
    "# resample（1mm*3）\n",
    "def resample_to_spacing(image_sitk, new_spacing=(1.0, 1.0, 1.0), interpolator=sitk.sitkLinear):\n",
    "    original_spacing = image_sitk.GetSpacing()\n",
    "    original_size = image_sitk.GetSize()\n",
    "    new_size = [\n",
    "        int(round(original_size[i] * (original_spacing[i] / new_spacing[i])))\n",
    "        for i in range(3)\n",
    "    ]\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetOutputSpacing(new_spacing)\n",
    "    resampler.SetSize(new_size)\n",
    "    resampler.SetOutputDirection(image_sitk.GetDirection())\n",
    "    resampler.SetOutputOrigin(image_sitk.GetOrigin())\n",
    "    resampler.SetInterpolator(interpolator)\n",
    "    return resampler.Execute(image_sitk)\n",
    "\n",
    "# main\n",
    "def load_aligned_ct_and_mask(patient_folder, target_spacing=(1.5, 1.5, 1.5)):\n",
    "    # Find asegmentation\n",
    "    seg_path = next((os.path.join(root, f) for root, _, files in os.walk(patient_folder)\n",
    "                     for f in files if \"segmentation\" in root.lower() and f.endswith(\".dcm\")), None)\n",
    "    if not seg_path:\n",
    "        return None, None, None\n",
    "\n",
    "    # Matched CT\n",
    "    uid = get_series_uid_from_seg(seg_path)\n",
    "    ct_folder = find_ct_folder_by_uid(patient_folder, uid)\n",
    "    if not ct_folder:\n",
    "        return None, None, None\n",
    "\n",
    "    # reading\n",
    "    ct_img = read_dicom_series(ct_folder)\n",
    "    seg_img = sitk.ReadImage(seg_path)\n",
    "\n",
    "    # resample\n",
    "    ct_img = resample_to_spacing(ct_img, new_spacing=target_spacing)\n",
    "\n",
    "    # resample segmentation\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetReferenceImage(ct_img)\n",
    "    resampler.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    seg_img = resampler.Execute(seg_img)\n",
    "\n",
    "    # get mask\n",
    "    mask = sitk.GetArrayFromImage(seg_img)\n",
    "    mask = (mask > 0)\n",
    "\n",
    "    # get CT image\n",
    "    image = sitk.GetArrayFromImage(ct_img)\n",
    "\n",
    "    return image, mask, target_spacing\n",
    "\n",
    "def find_segmentation_dcm(patient_folder):\n",
    "    \"\"\"\n",
    "    Recursively search under patient_folder to find the first subfolder containing the Segmentation keyword,\n",
    "    And there is DICOM file inside, return this dcm file path.\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(patient_folder):\n",
    "        if \"segmentation\" in root.lower():\n",
    "            dcm_files = [os.path.join(root, f) for f in files if f.lower().endswith(\".dcm\")]\n",
    "            if dcm_files:\n",
    "                return dcm_files[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "base_dir = os.path.join(DATA_DIR, \"dataset1\")\n",
    "\n",
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    if not patient_id.startswith(\"LUNG1-\"):\n",
    "        continue  # Only process the patient folders\n",
    "\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue\n",
    "\n",
    "    # Automatically find Segmentation DICOM\n",
    "    seg_dcm_path = find_segmentation_dcm(patient_path)\n",
    "    if seg_dcm_path is None:\n",
    "        print(f\"{patient_id} skipped: No segmentation found\")\n",
    "        continue\n",
    "\n",
    "    # load continued only when Segmentation was found\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "    if image is None or mask is None:\n",
    "        print(f\"{patient_id} skipped: failed to load image/mask\")\n",
    "        continue\n",
    "\n",
    "    # Standardized mask\n",
    "    mask = (mask > 0)\n",
    "\n",
    "    if np.sum(mask) < 100:\n",
    "        print(f\"{patient_id} skipped: ROI too small ({np.sum(mask)} voxels)\")\n",
    "        continue\n",
    "\n",
    "    roi = image * mask\n",
    "    print(f\"{patient_id} ROI volume shape: {roi.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775cdefd-dc95-4877-aef2-f3624b855f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, 5 patients processed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import measure\n",
    "from scipy.spatial.distance import pdist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data reading and preprocessing\n",
    "DATA_DIR = \"/mnt/e/Block_2/Machine_Learning/ASS_Part2/Project/testdata\"\n",
    "base_dir = os.path.join(DATA_DIR, \"dataset1\")\n",
    "\n",
    "# Normalize gray scale based on ROI\n",
    "def normalize_gray_roi_adaptive(image_np, mask_np, min_percentile=1, max_percentile=99):\n",
    "    roi = image_np[mask_np > 0]\n",
    "    if roi.size == 0:\n",
    "        return np.zeros_like(image_np)\n",
    "    vmin, vmax = np.percentile(roi, [min_percentile, max_percentile])\n",
    "    image_clipped = np.clip(image_np, vmin, vmax)\n",
    "    return (image_clipped - vmin) / (vmax - vmin + 1e-6)\n",
    "\n",
    "# get shape features\n",
    "def extract_shape_features(mask, spacing=(1.0, 1.0, 1.0)):\n",
    "    mask = mask.astype(np.float32)\n",
    "\n",
    "    if np.sum(mask) == 0:\n",
    "        return {\"volume_mm3\": 0, \"surface_mm2\": 0, \"max_diameter_mm\": 0, \"compactness\": 0}\n",
    "        \n",
    "    verts, faces, _, _ = measure.marching_cubes(mask, level=0.5, spacing=spacing)\n",
    "\n",
    "    surface_area = measure.mesh_surface_area(verts, faces)\n",
    "    voxel_volume = np.prod(spacing)\n",
    "    volume = np.sum(mask > 0) * voxel_volume\n",
    "\n",
    "    if len(verts) > 2000:\n",
    "        idx = np.random.choice(len(verts), size=2000, replace=False)\n",
    "        verts_sampled = verts[idx].astype(np.float32)\n",
    "    else:\n",
    "        verts_sampled = verts.astype(np.float32)\n",
    "\n",
    "    if len(verts_sampled) >= 2:\n",
    "        max_diameter = pdist(verts_sampled).max()\n",
    "    else:\n",
    "        max_diameter = 0.0\n",
    "\n",
    "    if volume > 0:\n",
    "        compactness = (surface_area ** 3) / (volume ** 2)\n",
    "    else:\n",
    "        compactness = 0.0\n",
    "\n",
    "    return {\n",
    "        \"volume_mm3\": volume,\n",
    "        \"surface_mm2\": surface_area,\n",
    "        \"max_diameter_mm\": max_diameter,\n",
    "        \"compactness\": compactness\n",
    "    }\n",
    "\n",
    "# get Texture Features: contrast, correlation, dissimilarity, homogeneity\n",
    "def gray_level_cooccurrence_features(img, mask, levels=32):\n",
    "    bin_img = (img * (levels - 1)).astype(np.uint8)\n",
    "    glcm = _calculate_glcm2(bin_img, mask, levels)\n",
    "    glcm = glcm / np.sum(glcm)\n",
    "\n",
    "    ix = np.arange(1, levels+1)[:, None, None].astype(np.float64)\n",
    "    iy = np.arange(1, levels+1)[None, :, None].astype(np.float64)\n",
    "\n",
    "    ux = np.mean(glcm, axis=0, keepdims=True)\n",
    "    uy = np.mean(glcm, axis=1, keepdims=True)\n",
    "    sigma_x = np.std(glcm, axis=0, keepdims=True)\n",
    "    sigma_y = np.std(glcm, axis=1, keepdims=True)\n",
    "\n",
    "    sigma_x[sigma_x < 1e-3] = 1e-3\n",
    "    sigma_y[sigma_y < 1e-3] = 1e-3\n",
    "\n",
    "    features = {\n",
    "        \"contrast\": np.mean(np.sum((ix - iy) ** 2 * glcm, axis=(0, 1))),\n",
    "        \"correlation\": np.mean(np.sum((ix * iy * glcm - ux * uy) / (sigma_x * sigma_y + 1e-6), axis=(0, 1))),\n",
    "        \"dissimilarity\": np.mean(np.sum(np.abs(ix - iy) * glcm, axis=(0, 1))),\n",
    "        \"homogeneity\": np.mean(np.sum(glcm / (1 + np.abs(ix - iy)), axis=(0, 1))),\n",
    "    }\n",
    "\n",
    "    return features\n",
    "\n",
    "# get Texture Features: GLCM in 13 directions\n",
    "def _calculate_glcm2(img, mask, nbins):\n",
    "    out = np.zeros((nbins, nbins, 13))\n",
    "    offsets = [\n",
    "        (1, 0, 0), (0, 1, 0), (0, 0, 1),\n",
    "        (1, 1, 0), (-1, 1, 0), (1, 0, 1),\n",
    "        (-1, 0, 1), (0, 1, 1), (0, -1, 1),\n",
    "        (1, 1, 1), (-1, 1, 1), (1, -1, 1), (1, 1, -1)\n",
    "    ]\n",
    "    matrix = np.array(img)\n",
    "    matrix[mask <= 0] = nbins\n",
    "    s = matrix.shape\n",
    "    bins = np.arange(0, nbins + 1)\n",
    "\n",
    "    for i, offset in enumerate(offsets):\n",
    "        matrix1 = np.ravel(matrix[\n",
    "            max(offset[0], 0):s[0]+min(offset[0], 0),\n",
    "            max(offset[1], 0):s[1]+min(offset[1], 0),\n",
    "            max(offset[2], 0):s[2]+min(offset[2], 0)\n",
    "        ])\n",
    "        matrix2 = np.ravel(matrix[\n",
    "            max(-offset[0], 0):s[0]+min(-offset[0], 0),\n",
    "            max(-offset[1], 0):s[1]+min(-offset[1], 0),\n",
    "            max(-offset[2], 0):s[2]+min(-offset[2], 0)\n",
    "        ])\n",
    "\n",
    "        try:\n",
    "            out[:, :, i] = np.histogram2d(matrix1, matrix2, bins=bins)[0]\n",
    "        except Exception as e:\n",
    "            print(f\"GLCM histogram failed for offset {offset}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return out\n",
    "\n",
    "# Main processing\n",
    "all_features = []\n",
    "\n",
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    if not patient_id.startswith(\"LUNG1-\"):\n",
    "        continue\n",
    "\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "    if image is None or mask is None:\n",
    "        print(f\"{patient_id} skip (no image or mask)\")\n",
    "        continue\n",
    "\n",
    "    mask = (mask > 0)  # Only the tumor area was retained\n",
    "\n",
    "    # Skip the minimal ROI\n",
    "    if np.sum(mask) < 100:\n",
    "        print(f\"{patient_id} skip: ROI too small ({np.sum(mask)} voxels)\")\n",
    "        continue\n",
    "\n",
    "    image = normalize_gray_roi_adaptive(image, mask)\n",
    "\n",
    "    # get segmentation\n",
    "    shape_feats = extract_shape_features(mask, spacing)\n",
    "    glcm_feats = gray_level_cooccurrence_features(image, mask)\n",
    "\n",
    "    features = {\"patient_id\": patient_id}\n",
    "    features.update(shape_feats)\n",
    "    features.update(glcm_feats)\n",
    "    all_features.append(features)\n",
    "\n",
    "# save result\n",
    "output_path = \"../result/features1.csv\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "df = pd.DataFrame(all_features)\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Done, {len(df)} patients processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0826a6-c83a-4503-9132-4f7012589559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
