{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10f805e9-5d2a-412c-806d-a875df15d90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ 选用实际像素尺寸 (192, 192)，共 526 张切片\n",
      "✔️ AMC-001 提取完毕\n",
      "→ 选用实际像素尺寸 (512, 512)，共 271 张切片\n",
      "✔️ AMC-002 提取完毕\n",
      "→ 选用实际像素尺寸 (512, 512)，共 567 张切片\n",
      "✔️ R01-006 提取完毕\n",
      "→ 选用实际像素尺寸 (512, 512)，共 483 张切片\n",
      "✔️ R01-023 提取完毕\n",
      "→ 选用实际像素尺寸 (512, 512)，共 531 张切片\n",
      "✔️ R01-024 提取完毕\n",
      "→ 选用实际像素尺寸 (512, 512)，共 376 张切片\n",
      "✔️ R01-026 提取完毕\n",
      "→ 选用实际像素尺寸 (512, 512)，共 1087 张切片\n",
      "✔️ R01-028 提取完毕\n",
      "所有影像特征已保存到 ../result/image_features_3d.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from monai.networks.nets import resnet\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "\n",
    "# ——— 1. DICOM 序列读取 & 归一化 —————————————————————\n",
    "def load_dicom_series(folder):\n",
    "    # 1) 递归搜所有 .dcm 文件\n",
    "    dcm_files = []\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for fn in files:\n",
    "            if fn.lower().endswith('.dcm'):\n",
    "                dcm_files.append(os.path.join(root, fn))\n",
    "    if not dcm_files:\n",
    "        raise ValueError(f\"No DICOMs found in {folder}\")\n",
    "\n",
    "    # 2) 读每个文件的 pixel_array.shape，按它分组\n",
    "    shape_groups = defaultdict(list)\n",
    "    for fp in dcm_files:\n",
    "        ds  = pydicom.dcmread(fp)\n",
    "        img = ds.pixel_array  # 实际 ndarray\n",
    "        shape_groups[img.shape].append(fp)\n",
    "\n",
    "    # 3) 选出文件数最多的那一组\n",
    "    best_shape, best_files = max(\n",
    "        shape_groups.items(), key=lambda x: len(x[1])\n",
    "    )\n",
    "    print(f\"→ 选用实际像素尺寸 {best_shape}，共 {len(best_files)} 张切片\")\n",
    "\n",
    "    # 4) 读取并按 InstanceNumber 排序\n",
    "    slices = []\n",
    "    for fp in best_files:\n",
    "        ds   = pydicom.dcmread(fp)\n",
    "        inst = getattr(ds, \"InstanceNumber\", 0)\n",
    "        img  = ds.pixel_array.astype(np.float32)\n",
    "        slices.append((inst, img))\n",
    "    slices.sort(key=lambda x: x[0])\n",
    "\n",
    "    # 5) 堆叠成 3D 体（D, H, W）\n",
    "    vol = np.stack([s[1] for s in slices], axis=0)\n",
    "\n",
    "    # 6) 归一化到 [0,1]\n",
    "    vol = (vol - vol.min()) / (vol.max() - vol.min())\n",
    "    return vol\n",
    "\n",
    "# ——— 2. 3D-ResNet 特征提取函数 ————————————————————\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net3d = resnet.resnet10(spatial_dims=3, n_input_channels=1, num_classes=1)\n",
    "net3d.fc = torch.nn.Identity()\n",
    "net3d = net3d.to(device).eval()\n",
    "\n",
    "def extract_features_3d(vol_np):\n",
    "    # vol_np: ndarray (D,H,W) in [0,1]\n",
    "    t = torch.from_numpy(vol_np).unsqueeze(0).unsqueeze(0).to(device)  \n",
    "    # now shape (1,1,D,H,W)\n",
    "    # resize to, say, (1,1,64,128,128):\n",
    "    t = F.interpolate(t, size=(64,128,128),\n",
    "                      mode='trilinear', align_corners=False)\n",
    "    with torch.no_grad():\n",
    "        feat = net3d(t)       # (1,512)\n",
    "    return feat.cpu().numpy().squeeze()  # (512,)\n",
    "\n",
    "# ——— 3. 批量处理所有患者 ————————————————————————\n",
    "root_dir = \"/mnt/e/Block_2/Machine_Learning/ASS_Part2/Project/testdata/dataset2\"\n",
    "case_ids = [d for d in os.listdir(root_dir)\n",
    "            if os.path.isdir(os.path.join(root_dir, d))]\n",
    "\n",
    "features = []\n",
    "ids       = []\n",
    "for cid in case_ids:\n",
    "    # 找到 CT 文件夹（假设名字里含 \"CT\"）\n",
    "    case_dir = os.path.join(root_dir, cid)\n",
    "    series = next((d for d in os.listdir(case_dir) if \"CT\" in d), None)\n",
    "    if series is None:\n",
    "        print(f\"{cid} 没找到 CT 文件夹，跳过\")\n",
    "        continue\n",
    "\n",
    "    vol = load_dicom_series(os.path.join(case_dir, series))\n",
    "    feat = extract_features_3d(vol)  \n",
    "    features.append(feat)\n",
    "    ids.append(cid)\n",
    "    print(f\"{cid} 提取完毕\")\n",
    "\n",
    "# ——— 4. 保存成 DataFrame 便于后续合并 —————————————\n",
    "df_img = pd.DataFrame(\n",
    "    features,\n",
    "    index=ids,\n",
    "    columns=[f\"img_feat_{i:03d}\" for i in range(features[0].shape[0])]\n",
    ")\n",
    "df_img.to_csv(\"../result/image_features_3d.csv\")\n",
    "print(\"所有影像特征已保存到 ../result/image_features_3d.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea193462-4eaa-47c4-8c9b-a60c1731ede7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共同样本数：5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Image Only ===\n",
      "f1       : 0.250 ± 0.250\n",
      "roc_auc  : 0.500 ± 0.000\n",
      "precision: 0.167 ± 0.167\n",
      "recall   : 0.500 ± 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RNA + Clinical ===\n",
      "f1       : 0.250 ± 0.250\n",
      "roc_auc  : 0.500 ± 0.000\n",
      "precision: 0.167 ± 0.167\n",
      "recall   : 0.500 ± 0.500\n",
      "\n",
      "=== Image + RNA + Clinical ===\n",
      "f1       : 0.250 ± 0.250\n",
      "roc_auc  : 0.500 ± 0.000\n",
      "precision: 0.167 ± 0.167\n",
      "recall   : 0.500 ± 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.compose         import ColumnTransformer\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.impute          import SimpleImputer\n",
    "from sklearn.preprocessing   import OneHotEncoder\n",
    "\n",
    "# 1. 读取三类特征矩阵\n",
    "df_img  = pd.read_csv(\"../result/image_features_3d.csv\", index_col=0)           # 样本×512\n",
    "df_rna  = pd.read_csv(\"../result/rnaseq_processed.csv\", index_col=0)            # 样本×n_genes\n",
    "df_clin = pd.read_csv(\"../result/clinical2_processed.csv\", index_col=\"Case ID\") # 样本×临床（含 Survival Status）\n",
    "\n",
    "# 2. 取交集样本\n",
    "common = df_clin.index.intersection(df_rna.index).intersection(df_img.index)\n",
    "print(f\"共同样本数：{len(common)}\")\n",
    "\n",
    "img_sub  = df_img.loc[common]\n",
    "rna_sub  = df_rna.loc[common]\n",
    "clin_sub = df_clin.loc[common]\n",
    "\n",
    "# 3. 构造标签 y\n",
    "y = (clin_sub[\"Survival Status\"] == \"Dead\").astype(int).values\n",
    "\n",
    "# 4. 处理临床特征：填补 + One-Hot\n",
    "#    4.1 分离数值列和分类列（去掉 Survival Status）\n",
    "clin_feats = clin_sub.drop(columns=\"Survival Status\")\n",
    "num_cols = clin_feats.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "cat_cols = clin_feats.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "#    4.2 构建预处理流水线\n",
    "pre_clin = ColumnTransformer([\n",
    "    (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "    (\"cat\", Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ]), cat_cols)\n",
    "], remainder=\"drop\")\n",
    "\n",
    "#    4.3 得到纯数值的临床矩阵\n",
    "X_clin_ohe = pre_clin.fit_transform(clin_feats)\n",
    "\n",
    "# 5. 构造三种特征集\n",
    "X_img     = img_sub.values            # (N, 512)\n",
    "X_rna     = rna_sub.values            # (N, n_genes)\n",
    "X_rnaclin = np.hstack([X_rna, X_clin_ohe])         # (N, n_genes + n_clin_ohe)\n",
    "X_all     = np.hstack([X_img, X_rna, X_clin_ohe])  # (N, 512 + n_genes + n_clin_ohe)\n",
    "\n",
    "# 6. 模型与 CV 配置\n",
    "cv      = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "clf     = RandomForestClassifier(\n",
    "              n_estimators=100,\n",
    "              min_samples_leaf=3,\n",
    "              random_state=42,\n",
    "              n_jobs=-1\n",
    "          )\n",
    "scoring = [\"f1\", \"roc_auc\", \"precision\", \"recall\"]\n",
    "\n",
    "# 7. 评估函数\n",
    "def eval_model(X, name):\n",
    "    scores = cross_validate(clf, X, y,\n",
    "                            cv=cv,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=False)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    for m in scoring:\n",
    "        arr = scores[f\"test_{m}\"]\n",
    "        print(f\"{m:9s}: {arr.mean():.3f} ± {arr.std():.3f}\")\n",
    "\n",
    "# 8. 分别评估三种方案\n",
    "eval_model(X_img,     \"Image Only\")\n",
    "eval_model(X_rnaclin, \"RNA + Clinical\")\n",
    "eval_model(X_all,     \"Image + RNA + Clinical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d70e0f2-34ca-4818-983d-d3457ba5ce62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMC-001 fail\n",
      "AMC-002 fail\n",
      "R01-006 ROI volume shape: (236, 333, 333)\n",
      "R01-023 ROI volume shape: (201, 287, 287)\n",
      "R01-024 ROI volume shape: (221, 280, 280)\n",
      "R01-026 ROI volume shape: (251, 273, 273)\n",
      "R01-028 ROI volume shape: (220, 293, 293)\n",
      "AMC-001 skip\n",
      "AMC-002 skip\n",
      "R01-006 features: {'volume_mm3': 4039.875, 'surface_mm2': 2238.3950887495143, 'max_diameter_mm': 31.4955010692827, 'compactness': 687.1861180282815}\n",
      "R01-023 features: {'volume_mm3': 59032.125, 'surface_mm2': 16694.84371499259, 'max_diameter_mm': 87.84357783922867, 'compactness': 1335.2735296617432}\n",
      "R01-024 features: {'volume_mm3': 4826.25, 'surface_mm2': 2425.9580374564475, 'max_diameter_mm': 44.84540438975412, 'compactness': 612.95730355034}\n",
      "R01-026 features: {'volume_mm3': 3847.5, 'surface_mm2': 1861.9637920419855, 'max_diameter_mm': 29.00281781556549, 'compactness': 436.0702282359349}\n",
      "R01-028 features: {'volume_mm3': 29764.125, 'surface_mm2': 7040.110005083245, 'max_diameter_mm': 60.01313895818942, 'compactness': 393.86926827557215}\n",
      "Done,5 in total\n"
     ]
    }
   ],
   "source": [
    "import os, pydicom, numpy as np, SimpleITK as sitk\n",
    "\n",
    "# get 3D volume\n",
    "def read_dicom_series(folder_path):\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    dicom_names = reader.GetGDCMSeriesFileNames(folder_path)\n",
    "    reader.SetFileNames(dicom_names)\n",
    "    return reader.Execute()\n",
    "\n",
    "# get CT Series UID from segmentation\n",
    "def get_series_uid_from_seg(seg_path):\n",
    "    return pydicom.dcmread(seg_path).ReferencedSeriesSequence[0].SeriesInstanceUID\n",
    "\n",
    "# matching UID\n",
    "def find_ct_folder_by_uid(folder, uid):\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(\".dcm\"):\n",
    "                try:\n",
    "                    if pydicom.dcmread(os.path.join(root, f), stop_before_pixels=True).SeriesInstanceUID == uid:\n",
    "                        return root\n",
    "                except: continue\n",
    "    return None\n",
    "\n",
    "# calculate Z-coordinate\n",
    "def get_z_coords(sitk_img):\n",
    "    sz, sp, org, dir3 = sitk_img.GetSize(), sitk_img.GetSpacing(), sitk_img.GetOrigin(), sitk_img.GetDirection()\n",
    "    return [org[2] + i * sp[2] * dir3[8] for i in range(sz[2])]\n",
    "\n",
    "# matching z\n",
    "def align_segmentation_by_z(seg_img, seg_z, ct_z):\n",
    "    zset = set(round(z, 1) for z in ct_z)\n",
    "    return sitk.GetArrayFromImage(seg_img)[[i for i, z in enumerate(seg_z) if round(z, 1) in zset]]\n",
    "\n",
    "# resample（1mm*3）\n",
    "def resample_to_spacing(image_sitk, new_spacing=(1.0, 1.0, 1.0), interpolator=sitk.sitkLinear):\n",
    "    original_spacing = image_sitk.GetSpacing()\n",
    "    original_size = image_sitk.GetSize()\n",
    "    new_size = [\n",
    "        int(round(original_size[i] * (original_spacing[i] / new_spacing[i])))\n",
    "        for i in range(3)\n",
    "    ]\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetOutputSpacing(new_spacing)\n",
    "    resampler.SetSize(new_size)\n",
    "    resampler.SetOutputDirection(image_sitk.GetDirection())\n",
    "    resampler.SetOutputOrigin(image_sitk.GetOrigin())\n",
    "    resampler.SetInterpolator(interpolator)\n",
    "    return resampler.Execute(image_sitk)\n",
    "\n",
    "# normalise to [0,1]\n",
    "def normalize_gray_roi_adaptive(image_np, mask_np, min_percentile=1, max_percentile=99):\n",
    "    roi = image_np[mask_np > 0]\n",
    "    if roi.size == 0:\n",
    "        return np.zeros_like(image_np)\n",
    "    vmin, vmax = np.percentile(roi, [min_percentile, max_percentile])\n",
    "    image_clipped = np.clip(image_np, vmin, vmax)\n",
    "    return (image_clipped - vmin) / (vmax - vmin + 1e-6)\n",
    "\n",
    "# main\n",
    "def load_aligned_ct_and_mask(patient_folder, target_spacing=(1.5, 1.5, 1.5)):\n",
    "    seg_path = next((os.path.join(root, f) for root, _, files in os.walk(patient_folder)\n",
    "                     for f in files if \"segmentation\" in root.lower() and f.endswith(\".dcm\")), None)\n",
    "    if not seg_path: return None, None, None\n",
    "\n",
    "    uid = get_series_uid_from_seg(seg_path)\n",
    "    ct_folder = find_ct_folder_by_uid(patient_folder, uid)\n",
    "    if not ct_folder: return None, None, None\n",
    "\n",
    "    ct_img = read_dicom_series(ct_folder)\n",
    "    seg_img = sitk.ReadImage(seg_path)\n",
    "\n",
    "    # Resample to same spacing (1mm)\n",
    "    ct_img = resample_to_spacing(ct_img, new_spacing=target_spacing)\n",
    "    \n",
    "    # resample segmentation\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetReferenceImage(ct_img)\n",
    "    resampler.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    seg_img = resampler.Execute(seg_img)\n",
    "\n",
    "    # z coordinate alignment\n",
    "    ct_z = get_z_coords(ct_img)\n",
    "    seg_z = get_z_coords(seg_img)\n",
    "    mask = align_segmentation_by_z(seg_img, seg_z, ct_z)\n",
    "\n",
    "    image = sitk.GetArrayFromImage(ct_img)\n",
    "    image = normalize_gray_roi_adaptive(image, mask)\n",
    "\n",
    "    # output\n",
    "    return image, mask, target_spacing\n",
    "\n",
    "base_dir = \"../testdata/dataset2\"\n",
    "\n",
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue  # skip non-folders\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "\n",
    "    if image is not None:\n",
    "        roi = image * (mask > 0)\n",
    "        print(f\"{patient_id} ROI volume shape: {roi.shape}\")\n",
    "    else:\n",
    "        print(f\"{patient_id} fail\")\n",
    "\n",
    "# Extraction of tumour 3D shape features based on marching cubes algorithm\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage as ski\n",
    "from skimage import io, data, filters, measure, morphology\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import skimage.measure\n",
    "from scipy.spatial.distance import  pdist\n",
    "\n",
    "def extract_shape_features(mask, spacing=(1.0, 1.0, 1.0)):\n",
    "    verts, faces, _, _ = measure.marching_cubes(mask, level=0.5, spacing=spacing)\n",
    "\n",
    "    # surface area\n",
    "    surface_area = measure.mesh_surface_area(verts, faces)\n",
    "\n",
    "    # volumetric\n",
    "    voxel_volume = np.prod(spacing)\n",
    "    volume = np.sum(mask > 0) * voxel_volume\n",
    "\n",
    "    # maximum diameter\n",
    "    if len(verts) >= 2:\n",
    "        max_diameter = pdist(verts).max()\n",
    "    else:\n",
    "        max_diameter = 0.0\n",
    "\n",
    "    # Compactness\n",
    "    if volume > 0:\n",
    "        compactness = (surface_area ** 3) / (volume ** 2)\n",
    "    else:\n",
    "        compactness = 0.0\n",
    "\n",
    "    return {\n",
    "        \"volume_mm3\": volume,\n",
    "        \"surface_mm2\": surface_area,\n",
    "        \"max_diameter_mm\": max_diameter,\n",
    "        \"compactness\": compactness\n",
    "    }\n",
    "\n",
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "    if image is None or mask is None:\n",
    "        print(f\"{patient_id} skip\")\n",
    "        continue\n",
    "\n",
    "    features = extract_shape_features(mask, spacing)\n",
    "    print(f\"{patient_id} features:\", features)\n",
    "\n",
    "# GLCM\n",
    "def gray_level_cooccurrence_features(img, mask, levels=32):\n",
    "    bin_img = (img * (levels - 1)).astype(np.uint8)\n",
    "    glcm = _calculate_glcm2(bin_img, mask, levels)\n",
    "    glcm = glcm / np.sum(glcm)\n",
    "\n",
    "    ix = np.arange(1, levels+1)[:, None, None].astype(np.float64)\n",
    "    iy = np.arange(1, levels+1)[None, :, None].astype(np.float64)\n",
    "\n",
    "    ux = np.mean(glcm, axis=0, keepdims=True)\n",
    "    uy = np.mean(glcm, axis=1, keepdims=True)\n",
    "    sigma_x = np.std(glcm, axis=0, keepdims=True)\n",
    "    sigma_y = np.std(glcm, axis=1, keepdims=True)\n",
    "\n",
    "    # downscale protection\n",
    "    sigma_x[sigma_x < 1e-3] = 1e-3\n",
    "    sigma_y[sigma_y < 1e-3] = 1e-3\n",
    "\n",
    "    features = {\n",
    "        \"contrast\": np.mean(np.sum((ix - iy) ** 2 * glcm, axis=(0, 1))),\n",
    "        \"correlation\": np.mean(np.sum((ix * iy * glcm - ux * uy) / (sigma_x * sigma_y + 1e-6), axis=(0, 1))),\n",
    "        \"dissimilarity\": np.mean(np.sum(np.abs(ix - iy) * glcm, axis=(0, 1))),\n",
    "        \"homogeneity\": np.mean(np.sum(glcm / (1 + np.abs(ix - iy)), axis=(0, 1))),\n",
    "    }\n",
    "\n",
    "    return features\n",
    "\n",
    "# GLCM2\n",
    "def _calculate_glcm2(img, mask, nbins):\n",
    "    out = np.zeros((nbins, nbins, 13))\n",
    "    offsets = [\n",
    "        (1, 0, 0), (0, 1, 0), (0, 0, 1),\n",
    "        (1, 1, 0), (-1, 1, 0), (1, 0, 1),\n",
    "        (-1, 0, 1), (0, 1, 1), (0, -1, 1),\n",
    "        (1, 1, 1), (-1, 1, 1), (1, -1, 1), (1, 1, -1)\n",
    "    ]\n",
    "    matrix = np.array(img)\n",
    "    matrix[mask <= 0] = nbins\n",
    "    s = matrix.shape\n",
    "    bins = np.arange(0, nbins + 1)\n",
    "\n",
    "    for i, offset in enumerate(offsets):\n",
    "        matrix1 = np.ravel(matrix[max(offset[0], 0):s[0]+min(offset[0], 0),\n",
    "                                  max(offset[1], 0):s[1]+min(offset[1], 0),\n",
    "                                  max(offset[2], 0):s[2]+min(offset[2], 0)])\n",
    "\n",
    "        matrix2 = np.ravel(matrix[max(-offset[0], 0):s[0]+min(-offset[0], 0),\n",
    "                                  max(-offset[1], 0):s[1]+min(-offset[1], 0),\n",
    "                                  max(-offset[2], 0):s[2]+min(-offset[2], 0)])\n",
    "\n",
    "        try:\n",
    "            out[:, :, i] = np.histogram2d(matrix1, matrix2, bins=bins)[0]\n",
    "        except Exception as e:\n",
    "            print(f\"GLCM histogram failed for offset {offset}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return out\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = \"../testdata/dataset2\"\n",
    "all_features = []\n",
    "\n",
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    if not patient_id.startswith(\"R01-\"):\n",
    "        continue\n",
    "\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "\n",
    "    if image is not None and mask is not None:\n",
    "        image = normalize_gray_roi_adaptive(image, mask)\n",
    "        glcm = gray_level_cooccurrence_features(image, mask)\n",
    "\n",
    "        glcm[\"patient_id\"] = patient_id\n",
    "        all_features.append(glcm)\n",
    "    else:\n",
    "        print(f\"{patient_id} skip\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "base_dir = \"../testdata/dataset2\"\n",
    "all_features = []\n",
    "\n",
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    if not patient_id.startswith(\"R01-\"):\n",
    "        continue\n",
    "\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "    if image is None or mask is None:\n",
    "        print(f\"{patient_id} skip\")\n",
    "        continue\n",
    "\n",
    "    image = normalize_gray_roi_adaptive(image, mask)\n",
    "    shape_feats = extract_shape_features(mask, spacing)\n",
    "    glcm_feats = gray_level_cooccurrence_features(image, mask)\n",
    "\n",
    "    features = {\"patient_id\": patient_id}\n",
    "    features.update(shape_feats)\n",
    "    features.update(glcm_feats)\n",
    "    all_features.append(features)\n",
    "\n",
    "# Save the result as a csv file\n",
    "output_path = \"../result/combined_features.csv\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "df = pd.DataFrame(all_features)\n",
    "df.to_csv(\"../result/features2.csv\", index=False)\n",
    "print(f\"Done,{len(df)} in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "563fe6d0-0134-44b3-b7be-32db16a0ff1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共同样本数：5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Image Only ===\n",
      "f1       : 0.250 ± 0.250\n",
      "roc_auc  : 0.500 ± 0.000\n",
      "precision: 0.167 ± 0.167\n",
      "recall   : 0.500 ± 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RNA Only ===\n",
      "f1       : 0.250 ± 0.250\n",
      "roc_auc  : 0.500 ± 0.000\n",
      "precision: 0.167 ± 0.167\n",
      "recall   : 0.500 ± 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Clinical Only ===\n",
      "f1       : 0.250 ± 0.250\n",
      "roc_auc  : 0.500 ± 0.000\n",
      "precision: 0.167 ± 0.167\n",
      "recall   : 0.500 ± 0.500\n",
      "\n",
      "=== Image + RNA + Clinical ===\n",
      "f1       : 0.250 ± 0.250\n",
      "roc_auc  : 0.500 ± 0.000\n",
      "precision: 0.167 ± 0.167\n",
      "recall   : 0.500 ± 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose         import ColumnTransformer\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.impute          import SimpleImputer\n",
    "from sklearn.preprocessing   import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "\n",
    "# 1. 读取特征矩阵\n",
    "df_img  = pd.read_csv(\"../result/features2.csv\",       index_col=\"patient_id\")  # 手动提取的影像特征\n",
    "df_rna  = pd.read_csv(\"../result/rnaseq_processed.csv\", index_col=0)            # 预处理好的 RNA\n",
    "df_clin = pd.read_csv(\"../result/clinical2_processed.csv\",\n",
    "                      index_col=\"Case ID\")                                      # 预处理好的临床（含 Survival Status）\n",
    "\n",
    "# 2. 取交集样本\n",
    "common = df_img.index.intersection(df_rna.index).intersection(df_clin.index)\n",
    "print(f\"共同样本数：{len(common)}\")\n",
    "\n",
    "img_sub  = df_img.loc[common]\n",
    "rna_sub  = df_rna.loc[common]\n",
    "clin_sub = df_clin.loc[common]\n",
    "\n",
    "# 3. 构造标签 y（Dead=1, Alive=0）\n",
    "y = (clin_sub[\"Survival Status\"] == \"Dead\").astype(int).values\n",
    "\n",
    "# 4. 临床预处理：中位数/众数填补 + One-Hot\n",
    "#    分离数值列和分类列（去掉 Survival Status）\n",
    "clin_feats = clin_sub.drop(columns=\"Survival Status\")\n",
    "num_cols = clin_feats.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "cat_cols = clin_feats.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "pre_clin = ColumnTransformer([\n",
    "    (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "    (\"cat\", Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ]), cat_cols)\n",
    "], remainder=\"drop\")\n",
    "\n",
    "X_clin_ohe = pre_clin.fit_transform(clin_feats)  # shape = (N, n_clin_ohe)\n",
    "\n",
    "# 5. RNA 和影像标准化\n",
    "X_rna_scaled = StandardScaler().fit_transform(rna_sub.values)\n",
    "X_img_scaled = StandardScaler().fit_transform(img_sub.values)\n",
    "\n",
    "# 6. 构造四种特征集\n",
    "X_img_only     = X_img_scaled\n",
    "X_rna_only     = X_rna_scaled\n",
    "X_clin_only    = X_clin_ohe\n",
    "X_all_three    = np.hstack([X_img_scaled, X_rna_scaled, X_clin_ohe])\n",
    "\n",
    "# 7. 模型 & CV & 指标\n",
    "cv      = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "clf     = RandomForestClassifier(n_estimators=100,\n",
    "                                 min_samples_leaf=3,\n",
    "                                 random_state=42,\n",
    "                                 n_jobs=-1)\n",
    "scoring = [\"f1\", \"roc_auc\", \"precision\", \"recall\"]\n",
    "\n",
    "# 用来收集各模型结果\n",
    "results = []\n",
    "\n",
    "def eval_model(X, name):\n",
    "    scores = cross_validate(clf, X, y,\n",
    "                            cv=cv,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=False)\n",
    "    # 组装当前模型的各项指标均值和标准差\n",
    "    row = {\"model\": name}\n",
    "    for m in scoring:\n",
    "        arr = scores[f\"test_{m}\"]\n",
    "        row[f\"{m}_mean\"] = arr.mean()\n",
    "        row[f\"{m}_std\"]  = arr.std()\n",
    "    results.append(row)\n",
    "    # 同时打印到控制台\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    for m in scoring:\n",
    "        print(f\"{m:9s}: {row[f'{m}_mean']:.3f} ± {row[f'{m}_std']:.3f}\")\n",
    "\n",
    "# 8. 依次评估\n",
    "eval_model(X_img_only,  \"Image Only\")\n",
    "eval_model(X_rna_only,  \"RNA Only\")\n",
    "eval_model(X_clin_only, \"Clinical Only\")\n",
    "eval_model(X_all_three, \"Image + RNA + Clinical\")\n",
    "\n",
    "# 9. 保存所有结果到 CSV\n",
    "df_res = pd.DataFrame(results)\n",
    "os.makedirs(\"result\", exist_ok=True)\n",
    "df_res.to_csv(\"result/result2.csv\", index=False)\n",
    "print(f\"save as result/result2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19419493-ec55-488d-86f1-db0a2b9826d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
