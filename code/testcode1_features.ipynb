{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b278630f-fd93-49cb-9d29-800a63d495d5",
   "metadata": {},
   "source": [
    "PART 1 \n",
    "Dataset1\n",
    "Step 1:\n",
    "å¯¹æ¯ä¸ªç—…äººï¼Œè¯»å– CT å›¾åƒå’Œ segmentation maskï¼Œ\n",
    "è‡ªåŠ¨å¯¹é½ Z åæ ‡å¹¶è£å‰ªï¼Œ\n",
    "å¾—åˆ° image_3d å’Œ mask_3dï¼Œç”¨äºæ ROI ç‰¹å¾ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6e0a76f-cf52-48a1-a5cb-53e2d0905bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pydicom, numpy as np, SimpleITK as sitk\n",
    "\n",
    "# ä»ä¸€ä¸ª DICOM æ–‡ä»¶å¤¹è¯»å–ä¸º 3D å›¾åƒï¼ˆSimpleITK å¯¹è±¡ï¼‰\n",
    "def read_dicom_series(folder_path):\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    dicom_names = reader.GetGDCMSeriesFileNames(folder_path)\n",
    "    reader.SetFileNames(dicom_names)\n",
    "    return reader.Execute()\n",
    "\n",
    "# ä» segmentation æ–‡ä»¶ä¸­æå–å®ƒå¼•ç”¨çš„ CT å›¾åƒçš„ Series UID\n",
    "def get_series_uid_from_seg(seg_path):\n",
    "    return pydicom.dcmread(seg_path).ReferencedSeriesSequence[0].SeriesInstanceUID\n",
    "\n",
    "# é€’å½’æŸ¥æ‰¾ç»™å®šç›®å½•ä¸‹ï¼Œæ˜¯å¦æœ‰æŸä¸ª .dcm æ–‡ä»¶çš„ SeriesInstanceUID ä¸ç›®æ ‡ UID åŒ¹é…\n",
    "def find_ct_folder_by_uid(folder, uid):\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(\".dcm\"):\n",
    "                try:\n",
    "                    if pydicom.dcmread(os.path.join(root, f), stop_before_pixels=True).SeriesInstanceUID == uid:\n",
    "                        return root\n",
    "                except: continue\n",
    "    return None\n",
    "\n",
    "# è®¡ç®— 3D å›¾åƒä¸­æ¯ä¸€å±‚çš„çœŸå®ç©ºé—´ Z åæ ‡ï¼Œè€ƒè™‘æ–¹å‘çŸ©é˜µã€origin å’Œ spacing\n",
    "def get_z_coords(sitk_img):\n",
    "    sz, sp, org, dir3 = sitk_img.GetSize(), sitk_img.GetSpacing(), sitk_img.GetOrigin(), sitk_img.GetDirection()\n",
    "    return [org[2] + i * sp[2] * dir3[8] for i in range(sz[2])]\n",
    "\n",
    "# å°† segmentation å›¾åƒä¸­ Z åæ ‡ä¸åœ¨ CT å›¾ä¸­çš„é‚£éƒ¨åˆ†åˆ‡æ‰ï¼Œç¡®ä¿ä¸¤è€…çš„ Z å±‚åŒ¹é…\n",
    "def align_segmentation_by_z(seg_img, seg_z, ct_z):\n",
    "    zset = set(round(z, 1) for z in ct_z)\n",
    "    return sitk.GetArrayFromImage(seg_img)[[i for i, z in enumerate(seg_z) if round(z, 1) in zset]]\n",
    "\n",
    "# å°† CT æˆ– segmentation å›¾åƒé‡é‡‡æ ·ï¼ˆresampleï¼‰ä¸ºç»Ÿä¸€ spacingï¼ˆé»˜è®¤ 1mmÂ³ï¼‰ï¼Œä¿è¯ç©ºé—´å°ºåº¦ä¸€è‡´ã€‚\n",
    "def resample_to_spacing(image_sitk, new_spacing=(1.0, 1.0, 1.0), interpolator=sitk.sitkLinear):\n",
    "    original_spacing = image_sitk.GetSpacing()\n",
    "    original_size = image_sitk.GetSize()\n",
    "    new_size = [\n",
    "        int(round(original_size[i] * (original_spacing[i] / new_spacing[i])))\n",
    "        for i in range(3)\n",
    "    ]\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetOutputSpacing(new_spacing)\n",
    "    resampler.SetSize(new_size)\n",
    "    resampler.SetOutputDirection(image_sitk.GetDirection())\n",
    "    resampler.SetOutputOrigin(image_sitk.GetOrigin())\n",
    "    resampler.SetInterpolator(interpolator)\n",
    "    return resampler.Execute(image_sitk)\n",
    "\n",
    "# è£å‰ªHUå€¼èŒƒå›´å¹¶å½’ä¸€åŒ–åˆ°[0,1] (rescale)\n",
    "def normalize_gray_roi_adaptive(image_np, mask_np, min_percentile=1, max_percentile=99):\n",
    "    roi = image_np[mask_np > 0]\n",
    "    if roi.size == 0:\n",
    "        return np.zeros_like(image_np)  # å…¨éƒ¨å˜0é¿å…ç‚¸æ‰\n",
    "    vmin, vmax = np.percentile(roi, [min_percentile, max_percentile])\n",
    "    image_clipped = np.clip(image_np, vmin, vmax)\n",
    "    return (image_clipped - vmin) / (vmax - vmin + 1e-6)\n",
    "\n",
    "# ä¸»å‡½æ•°ï¼šæ‰¾åˆ°å¹¶è¯»å–CTå’Œsegmentationï¼Œresample,å¯¹é½zåæ ‡ï¼Œå½’ä¸€åŒ–ç°åº¦\n",
    "def load_aligned_ct_and_mask(patient_folder, target_spacing=(1.5, 1.5, 1.5)):\n",
    "    seg_path = next((os.path.join(root, f) for root, _, files in os.walk(patient_folder)\n",
    "                     for f in files if \"segmentation\" in root.lower() and f.endswith(\".dcm\")), None)\n",
    "    if not seg_path: return None, None, None\n",
    "\n",
    "    uid = get_series_uid_from_seg(seg_path)\n",
    "    ct_folder = find_ct_folder_by_uid(patient_folder, uid)\n",
    "    if not ct_folder: return None, None, None\n",
    "\n",
    "    # CT å’Œ segmentation åŸå§‹å›¾åƒ\n",
    "    ct_img = read_dicom_series(ct_folder)\n",
    "    seg_img = sitk.ReadImage(seg_path)\n",
    "\n",
    "    # Resample to same spacing (1mm)\n",
    "    ct_img = resample_to_spacing(ct_img, new_spacing=target_spacing)\n",
    "    \n",
    "    # ç”¨ CT å›¾ä½œä¸ºå‚è€ƒï¼Œresample segmentation\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetReferenceImage(ct_img)\n",
    "    resampler.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    seg_img = resampler.Execute(seg_img)\n",
    "\n",
    "    # Z åæ ‡å¯¹é½\n",
    "    ct_z = get_z_coords(ct_img)\n",
    "    seg_z = get_z_coords(seg_img)\n",
    "    mask = align_segmentation_by_z(seg_img, seg_z, ct_z)\n",
    "\n",
    "    image = sitk.GetArrayFromImage(ct_img)\n",
    "    image = normalize_gray_roi_adaptive(image, mask)\n",
    "\n",
    "    # æœ€ç»ˆè¾“å‡º\n",
    "    return image, mask, target_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa7335a5-7bc3-45d4-924b-e7a685d0d4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUNG1-002 ROI volume shape: (222, 333, 333)\n",
      "LUNG1-003 ROI volume shape: (214, 333, 333)\n",
      "LUNG1-005 ROI volume shape: (182, 333, 333)\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"../testdata/dataset1\"\n",
    "\n",
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue  # è·³è¿‡éæ–‡ä»¶å¤¹\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "\n",
    "    if image is not None:\n",
    "        roi = image * (mask > 0)\n",
    "        print(f\"{patient_id} ROI volume shape: {roi.shape}\")\n",
    "        # TODO: å¯åœ¨è¿™é‡Œæ·»åŠ ç‰¹å¾æå–ã€ä¿å­˜æˆªå›¾ã€æ”¶é›† CSV æ•°æ®ç­‰\n",
    "    else:\n",
    "        print(f\"{patient_id} æ— æ³•åŠ è½½æˆ–å¯¹é½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ca8dc-ae6a-4339-bfad-53891fb34683",
   "metadata": {},
   "source": [
    "Step 2:æ‰‹åŠ¨æå–ç‰¹å¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6c08a25-9eda-4bb0-abd6-f6526e4d239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºäº marching cubes ç®—æ³•æå–è‚¿ç˜¤ä¸‰ç»´å½¢çŠ¶ç‰¹å¾\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage as ski\n",
    "from skimage import io, data, filters, measure, morphology\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import skimage.measure\n",
    "from scipy.spatial.distance import  pdist\n",
    "\n",
    "def extract_shape_features(mask, spacing=(1.0, 1.0, 1.0)):\n",
    "    \"\"\"\n",
    "    è¾“å…¥ï¼š\n",
    "        mask: 3D äºŒå€¼æ•°ç»„ï¼Œå½¢å¦‚ (Z, H, W)ï¼Œè¡¨ç¤ºè‚¿ç˜¤åŒºåŸŸ\n",
    "        spacing: ä¸‰å…ƒç»„ (sz, sy, sx)ï¼Œè¡¨ç¤ºæ¯ä¸ª voxel çš„ç©ºé—´å¤§å°ï¼ˆå•ä½ï¼šmmï¼‰\n",
    "\n",
    "    è¾“å‡ºï¼š\n",
    "        ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å« volume, surface_area, max_diameter, compactness ç­‰\n",
    "    \"\"\"\n",
    "\n",
    "    # marching cubes: ç”Ÿæˆè‚¿ç˜¤è¡¨é¢ mesh\n",
    "    verts, faces, _, _ = measure.marching_cubes(mask, level=0.5, spacing=spacing)\n",
    "\n",
    "    # è¡¨é¢ç§¯ï¼ˆå•ä½ mmÂ²ï¼‰\n",
    "    surface_area = measure.mesh_surface_area(verts, faces)\n",
    "\n",
    "    # ä½“ç§¯ï¼ˆå•ä½ mmÂ³ï¼‰ï¼šmask ä¸­ä¸º 1 çš„ voxel æ€»æ•° Ã— voxel ä½“ç§¯\n",
    "    voxel_volume = np.prod(spacing)\n",
    "    volume = np.sum(mask > 0) * voxel_volume\n",
    "\n",
    "    # æœ€å¤§ç›´å¾„ï¼šç‚¹ä¸ç‚¹ä¹‹é—´æœ€å¤§æ¬§å‡ é‡Œå¾—è·ç¦»ï¼ˆå•ä½ mmï¼‰\n",
    "    if len(verts) >= 2:\n",
    "        max_diameter = pdist(verts).max()\n",
    "    else:\n",
    "        max_diameter = 0.0\n",
    "\n",
    "    # ç´§è‡´åº¦ï¼ˆè¡¨é¢ç§¯Â³ / ä½“ç§¯Â²ï¼‰ï¼šè¶Šå°è¶Šæ¥è¿‘çƒä½“\n",
    "    if volume > 0:\n",
    "        compactness = (surface_area ** 3) / (volume ** 2)\n",
    "    else:\n",
    "        compactness = 0.0\n",
    "\n",
    "    return {\n",
    "        \"volume_mm3\": volume,\n",
    "        \"surface_mm2\": surface_area,\n",
    "        \"max_diameter_mm\": max_diameter,\n",
    "        \"compactness\": compactness\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "510d9fbf-86d8-4483-b511-66b9a5288a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUNG1-005 features: {'volume_mm3': 319146.75, 'surface_mm2': 65147.50703303793, 'max_diameter_mm': 243.24066726883004, 'compactness': 2714.6419241472163}\n"
     ]
    }
   ],
   "source": [
    "# å®šä¹‰ä½ è¦å¤„ç†çš„ç—…äºº ID\n",
    "patient_ids = [\"LUNG1-005\"]\n",
    "base_dir = \"../testdata/dataset1\"  # æ›¿æ¢æˆä½ çš„çœŸå®è·¯å¾„\n",
    "\n",
    "for patient_id in patient_ids:\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "    if image is None or mask is None:\n",
    "        print(f\"{patient_id} åŠ è½½å¤±è´¥ï¼Œè·³è¿‡\")\n",
    "        continue\n",
    "\n",
    "    features = extract_shape_features(mask, spacing)\n",
    "    print(f\"{patient_id} features:\", features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1a74e69-d6e2-49fa-a836-8a2a3f147d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUNG1-002 features: {'volume_mm3': 515210.625, 'surface_mm2': 76237.54357674009, 'max_diameter_mm': 293.2212584678799, 'compactness': 1669.3102586993753}\n",
      "LUNG1-003 features: {'volume_mm3': 369727.875, 'surface_mm2': 60603.535128362884, 'max_diameter_mm': 274.6759559269997, 'compactness': 1628.2814872188887}\n",
      "LUNG1-005 features: {'volume_mm3': 319146.75, 'surface_mm2': 65147.50703303793, 'max_diameter_mm': 243.24066726883004, 'compactness': 2714.6419241472163}\n"
     ]
    }
   ],
   "source": [
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "    if image is None or mask is None:\n",
    "        print(f\"{patient_id} åŠ è½½å¤±è´¥ï¼Œè·³è¿‡\")\n",
    "        continue\n",
    "\n",
    "    features = extract_shape_features(mask, spacing)\n",
    "    print(f\"{patient_id} features:\", features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4c0a702-6e08-4aa7-93b7-226b1884a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_level_cooccurrence_features(img, mask, levels=32):\n",
    "    bin_img = (img * (levels - 1)).astype(np.uint8)\n",
    "    glcm = _calculate_glcm2(bin_img, mask, levels)\n",
    "    glcm = glcm / np.sum(glcm)\n",
    "\n",
    "    ix = np.arange(1, levels+1)[:, None, None].astype(np.float64)\n",
    "    iy = np.arange(1, levels+1)[None, :, None].astype(np.float64)\n",
    "\n",
    "    ux = np.mean(glcm, axis=0, keepdims=True)\n",
    "    uy = np.mean(glcm, axis=1, keepdims=True)\n",
    "    sigma_x = np.std(glcm, axis=0, keepdims=True)\n",
    "    sigma_y = np.std(glcm, axis=1, keepdims=True)\n",
    "\n",
    "    # ä¸‹é™ä¿æŠ¤\n",
    "    sigma_x[sigma_x < 1e-3] = 1e-3\n",
    "    sigma_y[sigma_y < 1e-3] = 1e-3\n",
    "\n",
    "    features = {\n",
    "        \"contrast\": np.mean(np.sum((ix - iy) ** 2 * glcm, axis=(0, 1))),\n",
    "        \"correlation\": np.mean(np.sum((ix * iy * glcm - ux * uy) / (sigma_x * sigma_y + 1e-6), axis=(0, 1))),\n",
    "        \"dissimilarity\": np.mean(np.sum(np.abs(ix - iy) * glcm, axis=(0, 1))),\n",
    "        \"homogeneity\": np.mean(np.sum(glcm / (1 + np.abs(ix - iy)), axis=(0, 1))),\n",
    "    }\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af3e7f13-cafd-4e2a-b6c5-353f27de3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_glcm2(img, mask, nbins):\n",
    "    out = np.zeros((nbins, nbins, 13))\n",
    "    offsets = [\n",
    "        (1, 0, 0), (0, 1, 0), (0, 0, 1),\n",
    "        (1, 1, 0), (-1, 1, 0), (1, 0, 1),\n",
    "        (-1, 0, 1), (0, 1, 1), (0, -1, 1),\n",
    "        (1, 1, 1), (-1, 1, 1), (1, -1, 1), (1, 1, -1)\n",
    "    ]\n",
    "    matrix = np.array(img)\n",
    "    matrix[mask <= 0] = nbins\n",
    "    s = matrix.shape\n",
    "    bins = np.arange(0, nbins + 1)\n",
    "\n",
    "    for i, offset in enumerate(offsets):\n",
    "        matrix1 = np.ravel(matrix[max(offset[0], 0):s[0]+min(offset[0], 0),\n",
    "                                  max(offset[1], 0):s[1]+min(offset[1], 0),\n",
    "                                  max(offset[2], 0):s[2]+min(offset[2], 0)])\n",
    "\n",
    "        matrix2 = np.ravel(matrix[max(-offset[0], 0):s[0]+min(-offset[0], 0),\n",
    "                                  max(-offset[1], 0):s[1]+min(-offset[1], 0),\n",
    "                                  max(-offset[2], 0):s[2]+min(-offset[2], 0)])\n",
    "\n",
    "        try:\n",
    "            out[:, :, i] = np.histogram2d(matrix1, matrix2, bins=bins)[0]\n",
    "        except Exception as e:\n",
    "            print(f\"GLCM histogram failed for offset {offset}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b819c4d3-4c32-49f0-8320-b90968486c04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¿å­˜å®Œæˆï¼Œå…±æå–ç‰¹å¾æ ·æœ¬æ•°: 5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = \"../testdata/dataset1\"\n",
    "all_features = []\n",
    "\n",
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    # è·³è¿‡éâ€œLUNG1-â€å‘½åçš„æ–‡ä»¶å¤¹\n",
    "    if not patient_id.startswith(\"LUNG1-\"):\n",
    "        continue\n",
    "\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "\n",
    "    if image is not None and mask is not None:\n",
    "        image = normalize_gray_roi_adaptive(image, mask)\n",
    "        glcm = gray_level_cooccurrence_features(image, mask)\n",
    "\n",
    "        glcm[\"patient_id\"] = patient_id\n",
    "        all_features.append(glcm)\n",
    "    else:\n",
    "        print(f\"{patient_id} åŠ è½½å¤±è´¥ï¼Œè·³è¿‡\")\n",
    "\n",
    "# ä¿å­˜ä¸º CSV æ–‡ä»¶\n",
    "df = pd.DataFrame(all_features)\n",
    "df.to_csv(\"../result/glcm_features1.csv\", index=False)\n",
    "print(\"ä¿å­˜å®Œæˆï¼Œå…±æå–ç‰¹å¾æ ·æœ¬æ•°:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28043708-3118-4cca-a212-300ad09b9747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¿å­˜æˆåŠŸï¼Œå…±å¤„ç† 3 ä¸ªç—…äºº\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "base_dir = \"../testdata/dataset1\"\n",
    "all_features = []\n",
    "\n",
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    if not patient_id.startswith(\"LUNG1-\"):\n",
    "        continue\n",
    "\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "    if image is None or mask is None:\n",
    "        print(f\"{patient_id} åŠ è½½å¤±è´¥ï¼Œè·³è¿‡\")\n",
    "        continue\n",
    "\n",
    "    image = normalize_gray_roi_adaptive(image, mask)\n",
    "    shape_feats = extract_shape_features(mask, spacing)\n",
    "    glcm_feats = gray_level_cooccurrence_features(image, mask)\n",
    "\n",
    "    features = {\"patient_id\": patient_id}\n",
    "    features.update(shape_feats)\n",
    "    features.update(glcm_feats)\n",
    "    all_features.append(features)\n",
    "\n",
    "# ä¿å­˜ä¸º CSV\n",
    "output_path = \"../result/combined_features.csv\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "df = pd.DataFrame(all_features)\n",
    "df.to_csv(\"../result/features1.csv\", index=False)\n",
    "print(f\"ä¿å­˜æˆåŠŸï¼Œå…±å¤„ç† {len(df)} ä¸ªç—…äºº\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1b5c3fa-9e46-4e15-a5b4-e7b7f6f1bd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¹³å‡å‡†ç¡®ç‡ï¼ˆLeave-One-Outï¼‰: 1.000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# ==== Step 1: è¯»å–æ•°æ® ====\n",
    "# æ›¿æ¢ä¸ºä½ æœ¬åœ°çš„è·¯å¾„ï¼ˆå¦‚æœä¸åœ¨å½“å‰ç›®å½•ï¼‰\n",
    "features_df = pd.read_csv(\"../result/features1.csv\")\n",
    "clinical_df = pd.read_csv(\"../testdata/dataset1/clinical1.csv\")\n",
    "\n",
    "# åªä¿ç•™å¿…è¦çš„æ ‡ç­¾åˆ—\n",
    "clinical_df = clinical_df[[\"PatientID\", \"deadstatus.event\"]]\n",
    "\n",
    "# ==== Step 2: åˆå¹¶æ ‡ç­¾ä¸å½±åƒç‰¹å¾ ====\n",
    "df = features_df.merge(clinical_df, left_on=\"patient_id\", right_on=\"PatientID\")\n",
    "\n",
    "# ==== Step 3: å‡†å¤‡æ¨¡å‹è¾“å…¥ ====\n",
    "X = df.drop(columns=[\"patient_id\", \"PatientID\", \"deadstatus.event\"])\n",
    "y = df[\"deadstatus.event\"]\n",
    "\n",
    "# ==== Step 4: æ„å»ºæ ‡å‡†åŒ– + éšæœºæ£®æ—çš„æ¨¡å‹æµæ°´çº¿ ====\n",
    "model = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "\n",
    "# ==== Step 5: Leave-One-Out äº¤å‰éªŒè¯ï¼ˆæ ·æœ¬å°‘æ—¶æ¨èï¼‰ ====\n",
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(model, X, y, cv=loo, scoring=\"accuracy\")\n",
    "\n",
    "# ==== Step 6: è¾“å‡ºå¹³å‡å‡†ç¡®ç‡ ====\n",
    "print(f\"å¹³å‡å‡†ç¡®ç‡ï¼ˆLeave-One-Outï¼‰: {scores.mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34c770-00fc-43eb-9871-54b69c8c695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFå»ºæ¨¡ï¼ŒK-Fäº¤å‰éªŒè¯\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ==== åŠ è½½æ•°æ® ====\n",
    "features_df = pd.read_csv(\"features1.csv\")     # æ›¿æ¢ä¸ºä½  HPC ä¸Šè·¯å¾„\n",
    "clinical_df = pd.read_csv(\"clinical1.csv\")\n",
    "\n",
    "# åªä¿ç•™æ ‡ç­¾\n",
    "labels_df = clinical_df[[\"PatientID\", \"deadstatus.event\"]].dropna()\n",
    "\n",
    "# ==== Stratified 5-Fold äº¤å‰éªŒè¯å™¨ ====\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ==== æ¨¡å‹ï¼šæ ‡å‡†åŒ– + éšæœºæ£®æ— ====\n",
    "def evaluate_model(X, y, name=\"model\"):\n",
    "    model = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    f1 = cross_val_score(model, X, y, cv=skf, scoring=\"f1\")\n",
    "    auc = cross_val_score(model, X, y, cv=skf, scoring=\"roc_auc\")\n",
    "    print(f\"ğŸ§ª {name}ï¼š\")\n",
    "    print(f\"  å¹³å‡ F1: {f1.mean():.3f}  æ¯æŠ˜: {f1}\")\n",
    "    print(f\"  å¹³å‡ AUC: {auc.mean():.3f}  æ¯æŠ˜: {auc}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af56179d-7cec-43a6-9b34-a0521e9e5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»…ç”¨å½±åƒ\n",
    "# åˆå¹¶æ ‡ç­¾\n",
    "df_a = features_df.merge(labels_df, left_on=\"patient_id\", right_on=\"PatientID\")\n",
    "X_a = df_a.drop(columns=[\"patient_id\", \"PatientID\", \"deadstatus.event\"])\n",
    "y_a = df_a[\"deadstatus.event\"]\n",
    "\n",
    "evaluate_model(X_a, y_a, name=\"m_img\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e6f75e-6a28-4b69-a554-ede2e51a15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»…ç”¨ä¸´åºŠ\n",
    "# ç­›æ‰æ— æ ‡ç­¾æˆ–æ— å…³å­—æ®µ\n",
    "clinical_features = clinical_df.drop(columns=[\"PatientID\", \"Survival.time\", \"deadstatus.event\"])\n",
    "df_b = labels_df.merge(clinical_features, left_on=\"PatientID\", right_index=True)\n",
    "X_b = df_b.drop(columns=[\"PatientID\", \"deadstatus.event\"]).fillna(0)\n",
    "y_b = df_b[\"deadstatus.event\"]\n",
    "\n",
    "evaluate_model(X_b, y_b, name=\"m_clinical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20535b8-6991-48ae-bb00-71dd8cdc8c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å½±åƒ+ä¸´åºŠ\n",
    "# åˆå¹¶æ‰€æœ‰ç‰¹å¾ + æ ‡ç­¾\n",
    "df_c = features_df.merge(clinical_df, left_on=\"patient_id\", right_on=\"PatientID\")\n",
    "X_c = df_c.drop(columns=[\"patient_id\", \"PatientID\", \"Survival.time\", \"deadstatus.event\"]).fillna(0)\n",
    "y_c = df_c[\"deadstatus.event\"]\n",
    "\n",
    "evaluate_model(X_c, y_c, name=\"m_iac\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
