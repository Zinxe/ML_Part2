{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b278630f-fd93-49cb-9d29-800a63d495d5",
   "metadata": {},
   "source": [
    "PART 1 \n",
    "Dataset1\n",
    "Step 1:\n",
    "对每个病人，读取 CT 图像和 segmentation mask，\n",
    "自动对齐 Z 坐标并裁剪，\n",
    "得到 image_3d 和 mask_3d，用于提 ROI 特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6e0a76f-cf52-48a1-a5cb-53e2d0905bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pydicom, numpy as np, SimpleITK as sitk\n",
    "\n",
    "# 从一个 DICOM 文件夹读取为 3D 图像（SimpleITK 对象）\n",
    "def read_dicom_series(folder_path):\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    dicom_names = reader.GetGDCMSeriesFileNames(folder_path)\n",
    "    reader.SetFileNames(dicom_names)\n",
    "    return reader.Execute()\n",
    "\n",
    "# 从 segmentation 文件中提取它引用的 CT 图像的 Series UID\n",
    "def get_series_uid_from_seg(seg_path):\n",
    "    return pydicom.dcmread(seg_path).ReferencedSeriesSequence[0].SeriesInstanceUID\n",
    "\n",
    "# 递归查找给定目录下，是否有某个 .dcm 文件的 SeriesInstanceUID 与目标 UID 匹配\n",
    "def find_ct_folder_by_uid(folder, uid):\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(\".dcm\"):\n",
    "                try:\n",
    "                    if pydicom.dcmread(os.path.join(root, f), stop_before_pixels=True).SeriesInstanceUID == uid:\n",
    "                        return root\n",
    "                except: continue\n",
    "    return None\n",
    "\n",
    "# 计算 3D 图像中每一层的真实空间 Z 坐标，考虑方向矩阵、origin 和 spacing\n",
    "def get_z_coords(sitk_img):\n",
    "    sz, sp, org, dir3 = sitk_img.GetSize(), sitk_img.GetSpacing(), sitk_img.GetOrigin(), sitk_img.GetDirection()\n",
    "    return [org[2] + i * sp[2] * dir3[8] for i in range(sz[2])]\n",
    "\n",
    "# 将 segmentation 图像中 Z 坐标不在 CT 图中的那部分切掉，确保两者的 Z 层匹配\n",
    "def align_segmentation_by_z(seg_img, seg_z, ct_z):\n",
    "    zset = set(round(z, 1) for z in ct_z)\n",
    "    return sitk.GetArrayFromImage(seg_img)[[i for i, z in enumerate(seg_z) if round(z, 1) in zset]]\n",
    "\n",
    "# 将 CT 或 segmentation 图像重采样（resample）为统一 spacing（默认 1mm³），保证空间尺度一致。\n",
    "def resample_to_spacing(image_sitk, new_spacing=(1.0, 1.0, 1.0), interpolator=sitk.sitkLinear):\n",
    "    original_spacing = image_sitk.GetSpacing()\n",
    "    original_size = image_sitk.GetSize()\n",
    "    new_size = [\n",
    "        int(round(original_size[i] * (original_spacing[i] / new_spacing[i])))\n",
    "        for i in range(3)\n",
    "    ]\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetOutputSpacing(new_spacing)\n",
    "    resampler.SetSize(new_size)\n",
    "    resampler.SetOutputDirection(image_sitk.GetDirection())\n",
    "    resampler.SetOutputOrigin(image_sitk.GetOrigin())\n",
    "    resampler.SetInterpolator(interpolator)\n",
    "    return resampler.Execute(image_sitk)\n",
    "\n",
    "# 裁剪HU值范围并归一化到[0,1] (rescale)\n",
    "def normalize_gray_roi_adaptive(image_np, mask_np, min_percentile=1, max_percentile=99):\n",
    "    roi = image_np[mask_np > 0]\n",
    "    if roi.size == 0:\n",
    "        return np.zeros_like(image_np)  # 全部变0避免炸掉\n",
    "    vmin, vmax = np.percentile(roi, [min_percentile, max_percentile])\n",
    "    image_clipped = np.clip(image_np, vmin, vmax)\n",
    "    return (image_clipped - vmin) / (vmax - vmin + 1e-6)\n",
    "\n",
    "# 主函数：找到并读取CT和segmentation，resample,对齐z坐标，归一化灰度\n",
    "def load_aligned_ct_and_mask(patient_folder, target_spacing=(1.5, 1.5, 1.5)):\n",
    "    seg_path = next((os.path.join(root, f) for root, _, files in os.walk(patient_folder)\n",
    "                     for f in files if \"segmentation\" in root.lower() and f.endswith(\".dcm\")), None)\n",
    "    if not seg_path: return None, None, None\n",
    "\n",
    "    uid = get_series_uid_from_seg(seg_path)\n",
    "    ct_folder = find_ct_folder_by_uid(patient_folder, uid)\n",
    "    if not ct_folder: return None, None, None\n",
    "\n",
    "    # CT 和 segmentation 原始图像\n",
    "    ct_img = read_dicom_series(ct_folder)\n",
    "    seg_img = sitk.ReadImage(seg_path)\n",
    "\n",
    "    # Resample to same spacing (1mm)\n",
    "    ct_img = resample_to_spacing(ct_img, new_spacing=target_spacing)\n",
    "    \n",
    "    # 用 CT 图作为参考，resample segmentation\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetReferenceImage(ct_img)\n",
    "    resampler.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    seg_img = resampler.Execute(seg_img)\n",
    "\n",
    "    # Z 坐标对齐\n",
    "    ct_z = get_z_coords(ct_img)\n",
    "    seg_z = get_z_coords(seg_img)\n",
    "    mask = align_segmentation_by_z(seg_img, seg_z, ct_z)\n",
    "\n",
    "    image = sitk.GetArrayFromImage(ct_img)\n",
    "    image = normalize_gray_roi_adaptive(image, mask)\n",
    "\n",
    "    # 最终输出\n",
    "    return image, mask, target_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa7335a5-7bc3-45d4-924b-e7a685d0d4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUNG1-002 ROI volume shape: (222, 333, 333)\n",
      "LUNG1-003 ROI volume shape: (214, 333, 333)\n",
      "LUNG1-005 ROI volume shape: (182, 333, 333)\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"../testdata/dataset1\"\n",
    "\n",
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue  # 跳过非文件夹\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "\n",
    "    if image is not None:\n",
    "        roi = image * (mask > 0)\n",
    "        print(f\"{patient_id} ROI volume shape: {roi.shape}\")\n",
    "        # TODO: 可在这里添加特征提取、保存截图、收集 CSV 数据等\n",
    "    else:\n",
    "        print(f\"{patient_id} 无法加载或对齐\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ca8dc-ae6a-4339-bfad-53891fb34683",
   "metadata": {},
   "source": [
    "Step 2:手动提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6c08a25-9eda-4bb0-abd6-f6526e4d239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于 marching cubes 算法提取肿瘤三维形状特征\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage as ski\n",
    "from skimage import io, data, filters, measure, morphology\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import skimage.measure\n",
    "from scipy.spatial.distance import  pdist\n",
    "\n",
    "def extract_shape_features(mask, spacing=(1.0, 1.0, 1.0)):\n",
    "    \"\"\"\n",
    "    输入：\n",
    "        mask: 3D 二值数组，形如 (Z, H, W)，表示肿瘤区域\n",
    "        spacing: 三元组 (sz, sy, sx)，表示每个 voxel 的空间大小（单位：mm）\n",
    "\n",
    "    输出：\n",
    "        一个字典，包含 volume, surface_area, max_diameter, compactness 等\n",
    "    \"\"\"\n",
    "\n",
    "    # marching cubes: 生成肿瘤表面 mesh\n",
    "    verts, faces, _, _ = measure.marching_cubes(mask, level=0.5, spacing=spacing)\n",
    "\n",
    "    # 表面积（单位 mm²）\n",
    "    surface_area = measure.mesh_surface_area(verts, faces)\n",
    "\n",
    "    # 体积（单位 mm³）：mask 中为 1 的 voxel 总数 × voxel 体积\n",
    "    voxel_volume = np.prod(spacing)\n",
    "    volume = np.sum(mask > 0) * voxel_volume\n",
    "\n",
    "    # 最大直径：点与点之间最大欧几里得距离（单位 mm）\n",
    "    if len(verts) >= 2:\n",
    "        max_diameter = pdist(verts).max()\n",
    "    else:\n",
    "        max_diameter = 0.0\n",
    "\n",
    "    # 紧致度（表面积³ / 体积²）：越小越接近球体\n",
    "    if volume > 0:\n",
    "        compactness = (surface_area ** 3) / (volume ** 2)\n",
    "    else:\n",
    "        compactness = 0.0\n",
    "\n",
    "    return {\n",
    "        \"volume_mm3\": volume,\n",
    "        \"surface_mm2\": surface_area,\n",
    "        \"max_diameter_mm\": max_diameter,\n",
    "        \"compactness\": compactness\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "510d9fbf-86d8-4483-b511-66b9a5288a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUNG1-005 features: {'volume_mm3': 319146.75, 'surface_mm2': 65147.50703303793, 'max_diameter_mm': 243.24066726883004, 'compactness': 2714.6419241472163}\n"
     ]
    }
   ],
   "source": [
    "# 定义你要处理的病人 ID\n",
    "patient_ids = [\"LUNG1-005\"]\n",
    "base_dir = \"../testdata/dataset1\"  # 替换成你的真实路径\n",
    "\n",
    "for patient_id in patient_ids:\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "    if image is None or mask is None:\n",
    "        print(f\"{patient_id} 加载失败，跳过\")\n",
    "        continue\n",
    "\n",
    "    features = extract_shape_features(mask, spacing)\n",
    "    print(f\"{patient_id} features:\", features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1a74e69-d6e2-49fa-a836-8a2a3f147d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUNG1-002 features: {'volume_mm3': 515210.625, 'surface_mm2': 76237.54357674009, 'max_diameter_mm': 293.2212584678799, 'compactness': 1669.3102586993753}\n",
      "LUNG1-003 features: {'volume_mm3': 369727.875, 'surface_mm2': 60603.535128362884, 'max_diameter_mm': 274.6759559269997, 'compactness': 1628.2814872188887}\n",
      "LUNG1-005 features: {'volume_mm3': 319146.75, 'surface_mm2': 65147.50703303793, 'max_diameter_mm': 243.24066726883004, 'compactness': 2714.6419241472163}\n"
     ]
    }
   ],
   "source": [
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "    if image is None or mask is None:\n",
    "        print(f\"{patient_id} 加载失败，跳过\")\n",
    "        continue\n",
    "\n",
    "    features = extract_shape_features(mask, spacing)\n",
    "    print(f\"{patient_id} features:\", features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4c0a702-6e08-4aa7-93b7-226b1884a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_level_cooccurrence_features(img, mask, levels=32):\n",
    "    bin_img = (img * (levels - 1)).astype(np.uint8)\n",
    "    glcm = _calculate_glcm2(bin_img, mask, levels)\n",
    "    glcm = glcm / np.sum(glcm)\n",
    "\n",
    "    ix = np.arange(1, levels+1)[:, None, None].astype(np.float64)\n",
    "    iy = np.arange(1, levels+1)[None, :, None].astype(np.float64)\n",
    "\n",
    "    ux = np.mean(glcm, axis=0, keepdims=True)\n",
    "    uy = np.mean(glcm, axis=1, keepdims=True)\n",
    "    sigma_x = np.std(glcm, axis=0, keepdims=True)\n",
    "    sigma_y = np.std(glcm, axis=1, keepdims=True)\n",
    "\n",
    "    # 下限保护\n",
    "    sigma_x[sigma_x < 1e-3] = 1e-3\n",
    "    sigma_y[sigma_y < 1e-3] = 1e-3\n",
    "\n",
    "    features = {\n",
    "        \"contrast\": np.mean(np.sum((ix - iy) ** 2 * glcm, axis=(0, 1))),\n",
    "        \"correlation\": np.mean(np.sum((ix * iy * glcm - ux * uy) / (sigma_x * sigma_y + 1e-6), axis=(0, 1))),\n",
    "        \"dissimilarity\": np.mean(np.sum(np.abs(ix - iy) * glcm, axis=(0, 1))),\n",
    "        \"homogeneity\": np.mean(np.sum(glcm / (1 + np.abs(ix - iy)), axis=(0, 1))),\n",
    "    }\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af3e7f13-cafd-4e2a-b6c5-353f27de3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_glcm2(img, mask, nbins):\n",
    "    out = np.zeros((nbins, nbins, 13))\n",
    "    offsets = [\n",
    "        (1, 0, 0), (0, 1, 0), (0, 0, 1),\n",
    "        (1, 1, 0), (-1, 1, 0), (1, 0, 1),\n",
    "        (-1, 0, 1), (0, 1, 1), (0, -1, 1),\n",
    "        (1, 1, 1), (-1, 1, 1), (1, -1, 1), (1, 1, -1)\n",
    "    ]\n",
    "    matrix = np.array(img)\n",
    "    matrix[mask <= 0] = nbins\n",
    "    s = matrix.shape\n",
    "    bins = np.arange(0, nbins + 1)\n",
    "\n",
    "    for i, offset in enumerate(offsets):\n",
    "        matrix1 = np.ravel(matrix[max(offset[0], 0):s[0]+min(offset[0], 0),\n",
    "                                  max(offset[1], 0):s[1]+min(offset[1], 0),\n",
    "                                  max(offset[2], 0):s[2]+min(offset[2], 0)])\n",
    "\n",
    "        matrix2 = np.ravel(matrix[max(-offset[0], 0):s[0]+min(-offset[0], 0),\n",
    "                                  max(-offset[1], 0):s[1]+min(-offset[1], 0),\n",
    "                                  max(-offset[2], 0):s[2]+min(-offset[2], 0)])\n",
    "\n",
    "        try:\n",
    "            out[:, :, i] = np.histogram2d(matrix1, matrix2, bins=bins)[0]\n",
    "        except Exception as e:\n",
    "            print(f\"GLCM histogram failed for offset {offset}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b819c4d3-4c32-49f0-8320-b90968486c04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存完成，共提取特征样本数: 5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = \"../testdata/dataset1\"\n",
    "all_features = []\n",
    "\n",
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    # 跳过非“LUNG1-”命名的文件夹\n",
    "    if not patient_id.startswith(\"LUNG1-\"):\n",
    "        continue\n",
    "\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "\n",
    "    if image is not None and mask is not None:\n",
    "        image = normalize_gray_roi_adaptive(image, mask)\n",
    "        glcm = gray_level_cooccurrence_features(image, mask)\n",
    "\n",
    "        glcm[\"patient_id\"] = patient_id\n",
    "        all_features.append(glcm)\n",
    "    else:\n",
    "        print(f\"{patient_id} 加载失败，跳过\")\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "df = pd.DataFrame(all_features)\n",
    "df.to_csv(\"../result/glcm_features1.csv\", index=False)\n",
    "print(\"保存完成，共提取特征样本数:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28043708-3118-4cca-a212-300ad09b9747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存成功，共处理 3 个病人\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "base_dir = \"../testdata/dataset1\"\n",
    "all_features = []\n",
    "\n",
    "for patient_id in sorted(os.listdir(base_dir)):\n",
    "    if not patient_id.startswith(\"LUNG1-\"):\n",
    "        continue\n",
    "\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    if not os.path.isdir(patient_path):\n",
    "        continue\n",
    "\n",
    "    image, mask, spacing = load_aligned_ct_and_mask(patient_path)\n",
    "    if image is None or mask is None:\n",
    "        print(f\"{patient_id} 加载失败，跳过\")\n",
    "        continue\n",
    "\n",
    "    image = normalize_gray_roi_adaptive(image, mask)\n",
    "    shape_feats = extract_shape_features(mask, spacing)\n",
    "    glcm_feats = gray_level_cooccurrence_features(image, mask)\n",
    "\n",
    "    features = {\"patient_id\": patient_id}\n",
    "    features.update(shape_feats)\n",
    "    features.update(glcm_feats)\n",
    "    all_features.append(features)\n",
    "\n",
    "# 保存为 CSV\n",
    "output_path = \"../result/combined_features.csv\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "df = pd.DataFrame(all_features)\n",
    "df.to_csv(\"../result/features1.csv\", index=False)\n",
    "print(f\"保存成功，共处理 {len(df)} 个病人\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1b5c3fa-9e46-4e15-a5b4-e7b7f6f1bd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均准确率（Leave-One-Out）: 1.000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# ==== Step 1: 读取数据 ====\n",
    "# 替换为你本地的路径（如果不在当前目录）\n",
    "features_df = pd.read_csv(\"../result/features1.csv\")\n",
    "clinical_df = pd.read_csv(\"../testdata/dataset1/clinical1.csv\")\n",
    "\n",
    "# 只保留必要的标签列\n",
    "clinical_df = clinical_df[[\"PatientID\", \"deadstatus.event\"]]\n",
    "\n",
    "# ==== Step 2: 合并标签与影像特征 ====\n",
    "df = features_df.merge(clinical_df, left_on=\"patient_id\", right_on=\"PatientID\")\n",
    "\n",
    "# ==== Step 3: 准备模型输入 ====\n",
    "X = df.drop(columns=[\"patient_id\", \"PatientID\", \"deadstatus.event\"])\n",
    "y = df[\"deadstatus.event\"]\n",
    "\n",
    "# ==== Step 4: 构建标准化 + 随机森林的模型流水线 ====\n",
    "model = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "\n",
    "# ==== Step 5: Leave-One-Out 交叉验证（样本少时推荐） ====\n",
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(model, X, y, cv=loo, scoring=\"accuracy\")\n",
    "\n",
    "# ==== Step 6: 输出平均准确率 ====\n",
    "print(f\"平均准确率（Leave-One-Out）: {scores.mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34c770-00fc-43eb-9871-54b69c8c695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF建模，K-F交叉验证\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ==== 加载数据 ====\n",
    "features_df = pd.read_csv(\"features1.csv\")     # 替换为你 HPC 上路径\n",
    "clinical_df = pd.read_csv(\"clinical1.csv\")\n",
    "\n",
    "# 只保留标签\n",
    "labels_df = clinical_df[[\"PatientID\", \"deadstatus.event\"]].dropna()\n",
    "\n",
    "# ==== Stratified 5-Fold 交叉验证器 ====\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ==== 模型：标准化 + 随机森林 ====\n",
    "def evaluate_model(X, y, name=\"model\"):\n",
    "    model = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    f1 = cross_val_score(model, X, y, cv=skf, scoring=\"f1\")\n",
    "    auc = cross_val_score(model, X, y, cv=skf, scoring=\"roc_auc\")\n",
    "    print(f\"🧪 {name}：\")\n",
    "    print(f\"  平均 F1: {f1.mean():.3f}  每折: {f1}\")\n",
    "    print(f\"  平均 AUC: {auc.mean():.3f}  每折: {auc}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af56179d-7cec-43a6-9b34-a0521e9e5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仅用影像\n",
    "# 合并标签\n",
    "df_a = features_df.merge(labels_df, left_on=\"patient_id\", right_on=\"PatientID\")\n",
    "X_a = df_a.drop(columns=[\"patient_id\", \"PatientID\", \"deadstatus.event\"])\n",
    "y_a = df_a[\"deadstatus.event\"]\n",
    "\n",
    "evaluate_model(X_a, y_a, name=\"m_img\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e6f75e-6a28-4b69-a554-ede2e51a15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仅用临床\n",
    "# 筛掉无标签或无关字段\n",
    "clinical_features = clinical_df.drop(columns=[\"PatientID\", \"Survival.time\", \"deadstatus.event\"])\n",
    "df_b = labels_df.merge(clinical_features, left_on=\"PatientID\", right_index=True)\n",
    "X_b = df_b.drop(columns=[\"PatientID\", \"deadstatus.event\"]).fillna(0)\n",
    "y_b = df_b[\"deadstatus.event\"]\n",
    "\n",
    "evaluate_model(X_b, y_b, name=\"m_clinical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20535b8-6991-48ae-bb00-71dd8cdc8c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 影像+临床\n",
    "# 合并所有特征 + 标签\n",
    "df_c = features_df.merge(clinical_df, left_on=\"patient_id\", right_on=\"PatientID\")\n",
    "X_c = df_c.drop(columns=[\"patient_id\", \"PatientID\", \"Survival.time\", \"deadstatus.event\"]).fillna(0)\n",
    "y_c = df_c[\"deadstatus.event\"]\n",
    "\n",
    "evaluate_model(X_c, y_c, name=\"m_iac\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
